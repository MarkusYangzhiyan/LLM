{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5eb8f542-bf81-47ed-9593-f6616233487a",
   "metadata": {},
   "source": [
    "## Qwen2.5-0.5B-Instruct 模型下载部署调用标准流程\n",
    "1. 下载必要的库：modelscope transformers torch accelerate   这里由于国内环境，我用modelscope下载\n",
    "2. 使用的包为：\n",
    "      - snapshot_download 来下载模型\n",
    "      - AuToModelForCausalLM，AutoTokenizer来加载模型    \n",
    "3. 确定模型的名称：Qwen/Qwen2.5-0.5B-Instruct, 下载模型保存到路径model_dir中\n",
    "4. 加载模型\n",
    "5. 准备数据：prompt 和 messages\n",
    "6. 将输入的数据进行apply_chat_template处理\n",
    "7. 将处理好的数据转化成tokens，变成model_inputs\n",
    "8. 生成回答的tokens，为generated_ids，并且只保留LLM回答的部分\n",
    "9. 将第八步的结果进行decode解码\n",
    "10. 输出最终的文本回答"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e2e33889-449d-4c99-b2b5-a150c97fb1f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from modelscope import snapshot_download\n",
    "from modelscope import AutoModelForCausalLM,AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4064b42e-7679-42c5-a0ea-6bbbda961401",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = \"Qwen/Qwen2.5-0.5B-Instruct\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3b70c07f-8035-4877-a3ed-32dd37bf2a75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading Model from https://www.modelscope.cn to directory: C:\\Users\\User\\.cache\\modelscope\\hub\\models\\Qwen\\Qwen2.5-0.5B-Instruct\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-30 14:01:09,220 - modelscope - INFO - Got 1 files, start to download ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02e4b12a9f7b47e0b43a366586cb08c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing 1 items:   0%|          | 0.00/1.00 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aeec47e7420f411184f4991a2229391d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading [model.safetensors]:   0%|          | 0.00/942M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-30 14:05:35,883 - modelscope - INFO - Download model 'Qwen/Qwen2.5-0.5B-Instruct' successfully.\n",
      "2025-12-30 14:05:35,899 - modelscope - INFO - Creating symbolic link [C:\\Users\\User\\.cache\\modelscope\\hub\\models\\Qwen\\Qwen2.5-0.5B-Instruct].\n",
      "2025-12-30 14:05:35,899 - modelscope - WARNING - Failed to create symbolic link C:\\Users\\User\\.cache\\modelscope\\hub\\models\\Qwen\\Qwen2.5-0.5B-Instruct for C:\\Users\\User\\.cache\\modelscope\\hub\\models\\Qwen\\Qwen2___5-0___5B-Instruct.\n"
     ]
    }
   ],
   "source": [
    "model_dir = snapshot_download(model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4bf11518-26ef-4036-bc8a-4442ba5f3ee2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\User\\\\.cache\\\\modelscope\\\\hub\\\\models\\\\Qwen\\\\Qwen2___5-0___5B-Instruct'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6236a21b-688b-44d0-8b24-35d863a9f89a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_dir,trsut_remote_code = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1a92be42-1cbe-42dc-8194-31b01ffd31dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Qwen2TokenizerFast(name_or_path='C:\\Users\\User\\.cache\\modelscope\\hub\\models\\Qwen\\Qwen2___5-0___5B-Instruct', vocab_size=151643, model_max_length=131072, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'eos_token': '<|im_end|>', 'pad_token': '<|endoftext|>', 'additional_special_tokens': ['<|im_start|>', '<|im_end|>', '<|object_ref_start|>', '<|object_ref_end|>', '<|box_start|>', '<|box_end|>', '<|quad_start|>', '<|quad_end|>', '<|vision_start|>', '<|vision_end|>', '<|vision_pad|>', '<|image_pad|>', '<|video_pad|>']}, clean_up_tokenization_spaces=False, added_tokens_decoder={\n",
       "\t151643: AddedToken(\"<|endoftext|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t151644: AddedToken(\"<|im_start|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t151645: AddedToken(\"<|im_end|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t151646: AddedToken(\"<|object_ref_start|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t151647: AddedToken(\"<|object_ref_end|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t151648: AddedToken(\"<|box_start|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t151649: AddedToken(\"<|box_end|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t151650: AddedToken(\"<|quad_start|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t151651: AddedToken(\"<|quad_end|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t151652: AddedToken(\"<|vision_start|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t151653: AddedToken(\"<|vision_end|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t151654: AddedToken(\"<|vision_pad|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t151655: AddedToken(\"<|image_pad|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t151656: AddedToken(\"<|video_pad|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t151657: AddedToken(\"<tool_call>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t151658: AddedToken(\"</tool_call>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t151659: AddedToken(\"<|fim_prefix|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t151660: AddedToken(\"<|fim_middle|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t151661: AddedToken(\"<|fim_suffix|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t151662: AddedToken(\"<|fim_pad|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t151663: AddedToken(\"<|repo_name|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t151664: AddedToken(\"<|file_sep|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "}\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7cfcb122-9555-4da6-9c22-637557e32c29",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_dir,\n",
    "    device_map = \"auto\",\n",
    "    torch_dtype = \"auto\",\n",
    "    trust_remote_code = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "088a989f-b1c8-4677-b70b-caf371530f30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Qwen2ForCausalLM(\n",
       "  (model): Qwen2Model(\n",
       "    (embed_tokens): Embedding(151936, 896)\n",
       "    (layers): ModuleList(\n",
       "      (0-23): 24 x Qwen2DecoderLayer(\n",
       "        (self_attn): Qwen2Attention(\n",
       "          (q_proj): Linear(in_features=896, out_features=896, bias=True)\n",
       "          (k_proj): Linear(in_features=896, out_features=128, bias=True)\n",
       "          (v_proj): Linear(in_features=896, out_features=128, bias=True)\n",
       "          (o_proj): Linear(in_features=896, out_features=896, bias=False)\n",
       "        )\n",
       "        (mlp): Qwen2MLP(\n",
       "          (gate_proj): Linear(in_features=896, out_features=4864, bias=False)\n",
       "          (up_proj): Linear(in_features=896, out_features=4864, bias=False)\n",
       "          (down_proj): Linear(in_features=4864, out_features=896, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): Qwen2RMSNorm((896,), eps=1e-06)\n",
       "        (post_attention_layernorm): Qwen2RMSNorm((896,), eps=1e-06)\n",
       "      )\n",
       "    )\n",
       "    (norm): Qwen2RMSNorm((896,), eps=1e-06)\n",
       "    (rotary_emb): Qwen2RotaryEmbedding()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=896, out_features=151936, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1959c986-7db0-41c5-bab3-4fac9822ded3",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"解释一下LM和LMM的区别是什么\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ad53b00f-ecfb-4a14-96b1-73db06cf400e",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    {\"role\":\"user\",\"content\":prompt}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f164bffb-07c1-4197-8566-effba756727e",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = tokenizer.apply_chat_template(\n",
    "    messages,\n",
    "    tokenize = False,\n",
    "    add_generation_prompt = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4408aab9-7d77-4279-a9a2-36f0e97a15f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<|im_start|>system\\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\\n<|im_start|>user\\n解释一下LM和LMM的区别是什么<|im_end|>\\n<|im_start|>assistant\\n'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9583a5a4-becf-4bbf-be3b-5538d741c162",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_inputs = tokenizer([text],return_tensors = 'pt').to(model.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e75c1ac7-2a9e-4f2a-b97d-48f13efc9046",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[151644,   8948,    198,   2610,    525,   1207,  16948,     11,   3465,\n",
       "            553,  54364,  14817,     13,   1446,    525,    264,  10950,  17847,\n",
       "             13, 151645,    198, 151644,    872,    198, 104136, 100158,  10994,\n",
       "          33108,     43,   8035, 109226, 102021, 151645,    198, 151644,  77091,\n",
       "            198]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a06462af-999f-4ea7-affc-3cf8db4ffc95",
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_ids = model.generate(\n",
    "    **model_inputs,\n",
    "    max_new_tokens = 512\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "179fe2cc-731b-4139-a47e-1ef6c3c9c193",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[151644,   8948,    198,   2610,    525,   1207,  16948,     11,   3465,\n",
       "            553,  54364,  14817,     13,   1446,    525,    264,  10950,  17847,\n",
       "             13, 151645,    198, 151644,    872,    198, 104136, 100158,  10994,\n",
       "          33108,     43,   8035, 109226, 102021, 151645,    198, 151644,  77091,\n",
       "            198,  10994,  58143,    444,   8035,  54851, 101441, 101970, 104949,\n",
       "         104034,  39907,   3837, 104017,  18493,  54542,  99795, 102064,  86119,\n",
       "          13343, 114046, 100772,  33108, 105255, 102122,   3407,     16,     13,\n",
       "           3070,  10994,   9909,  13806,   4903,   7552,    334,  28311,    256,\n",
       "            481,  46414,   6567,  44401,  24300,  99558, 100020, 100146,  43959,\n",
       "         108704, 108530,   1773,  77557,  96050, 102182, 105395,   5373, 104934,\n",
       "         101042,   5373, 111436,  72448,  49567,  88802,  15946,   3837,  10994,\n",
       "            220,  36993, 104482, 104538, 108725,  99689,  57191,  99534,  72881,\n",
       "           9370, 109091,   8997,    256,    481,  46414,  43589,  66017, 112452,\n",
       "         104210,  98841, 104034, 109824, 104949,  36407,  43959,   9370,   1773,\n",
       "          99652, 102119,  37029,  98841,  91282,   9370, 104190, 100631, 105149,\n",
       "           9370, 107018,  36407, 103930,  43959,   9370, 108704,  43815,   8997,\n",
       "            256,    481,  46414,  26853,    107,  23031, 100751,  43959,  82025,\n",
       "           5373,  85641,   5373, 100370, 113464, 109963, 108704,   3407,     17,\n",
       "             13,   3070,     43,   8035,   9909,  34253,  11434,   4903,   7552,\n",
       "            334,  28311,    256,    481,    444,   8035,  74866,    116,  56006,\n",
       "          34204,  46414,  72669,  20929, 102553,   3837, 113667, 100134,  26939,\n",
       "          33126, 104653, 100032,  90395, 100136,  73670,  71817,  33126, 106888,\n",
       "          88802,   1773,     43,   8035,  86009,  99373, 100006,  43959, 108704,\n",
       "           3837, 104468, 101128, 102285,  16744,  27369,   3837, 100636, 115167,\n",
       "         104538,  92894, 109963,  99795, 102064,  86119,   8997,    256,    481,\n",
       "            444,   8035,    220,  67338, 101514,  20074, 104034,  36407, 100627,\n",
       "          41146,  32664,  99604, 100650, 100032, 108894,  99788,   1773,     43,\n",
       "           8035,  32181,    246, 100629, 108858, 105595, 106712, 113272,  99788,\n",
       "           3837, 109608, 101928, 102181,  86119,  13343, 107837,  38035,   8997,\n",
       "            256,    481,    444,   8035,  26853,    107,  23031, 110645, 100646,\n",
       "          99892, 100650,   3837,  29524, 107553, 102450,   5373, 105761, 102450,\n",
       "           5373,  99795, 102064, 115167, 105051,  72448,  49567,   3407, 102050,\n",
       "          99883,   3837,  10994,  89982,  30534, 100751,  43959, 108704,   3837,\n",
       "          68536,    444,   8035,  19468,    247,  20412,  26288, 104949,  99361,\n",
       "         104491,   3837,  73670,  71817, 101896, 100011,  33108, 106888,  88802,\n",
       "           3837, 100630, 116509, 101128,   5373, 113272,   5373, 100134,  49567,\n",
       "           1773, 107051, 100132,  99795, 102064,  54542, 104799, 110025,   3837,\n",
       "         109100,  99320, 100057,   1773, 151645]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generated_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d6bfaf3e-51ae-43e0-a0fd-5a9534de28dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_ids = [\n",
    "    output_ids[len(input_ids):] for input_ids,output_ids in zip(model_inputs.input_ids,generated_ids)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d56202cf-bc63-4a77-b872-818d90601150",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([ 10994,  58143,    444,   8035,  54851, 101441, 101970, 104949, 104034,\n",
       "          39907,   3837, 104017,  18493,  54542,  99795, 102064,  86119,  13343,\n",
       "         114046, 100772,  33108, 105255, 102122,   3407,     16,     13,   3070,\n",
       "          10994,   9909,  13806,   4903,   7552,    334,  28311,    256,    481,\n",
       "          46414,   6567,  44401,  24300,  99558, 100020, 100146,  43959, 108704,\n",
       "         108530,   1773,  77557,  96050, 102182, 105395,   5373, 104934, 101042,\n",
       "           5373, 111436,  72448,  49567,  88802,  15946,   3837,  10994,    220,\n",
       "          36993, 104482, 104538, 108725,  99689,  57191,  99534,  72881,   9370,\n",
       "         109091,   8997,    256,    481,  46414,  43589,  66017, 112452, 104210,\n",
       "          98841, 104034, 109824, 104949,  36407,  43959,   9370,   1773,  99652,\n",
       "         102119,  37029,  98841,  91282,   9370, 104190, 100631, 105149,   9370,\n",
       "         107018,  36407, 103930,  43959,   9370, 108704,  43815,   8997,    256,\n",
       "            481,  46414,  26853,    107,  23031, 100751,  43959,  82025,   5373,\n",
       "          85641,   5373, 100370, 113464, 109963, 108704,   3407,     17,     13,\n",
       "           3070,     43,   8035,   9909,  34253,  11434,   4903,   7552,    334,\n",
       "          28311,    256,    481,    444,   8035,  74866,    116,  56006,  34204,\n",
       "          46414,  72669,  20929, 102553,   3837, 113667, 100134,  26939,  33126,\n",
       "         104653, 100032,  90395, 100136,  73670,  71817,  33126, 106888,  88802,\n",
       "           1773,     43,   8035,  86009,  99373, 100006,  43959, 108704,   3837,\n",
       "         104468, 101128, 102285,  16744,  27369,   3837, 100636, 115167, 104538,\n",
       "          92894, 109963,  99795, 102064,  86119,   8997,    256,    481,    444,\n",
       "           8035,    220,  67338, 101514,  20074, 104034,  36407, 100627,  41146,\n",
       "          32664,  99604, 100650, 100032, 108894,  99788,   1773,     43,   8035,\n",
       "          32181,    246, 100629, 108858, 105595, 106712, 113272,  99788,   3837,\n",
       "         109608, 101928, 102181,  86119,  13343, 107837,  38035,   8997,    256,\n",
       "            481,    444,   8035,  26853,    107,  23031, 110645, 100646,  99892,\n",
       "         100650,   3837,  29524, 107553, 102450,   5373, 105761, 102450,   5373,\n",
       "          99795, 102064, 115167, 105051,  72448,  49567,   3407, 102050,  99883,\n",
       "           3837,  10994,  89982,  30534, 100751,  43959, 108704,   3837,  68536,\n",
       "            444,   8035,  19468,    247,  20412,  26288, 104949,  99361, 104491,\n",
       "           3837,  73670,  71817, 101896, 100011,  33108, 106888,  88802,   3837,\n",
       "         100630, 116509, 101128,   5373, 113272,   5373, 100134,  49567,   1773,\n",
       "         107051, 100132,  99795, 102064,  54542, 104799, 110025,   3837, 109100,\n",
       "          99320, 100057,   1773, 151645])]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generated_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "828c1c17-3d99-4b69-8bf0-0ee19514ab41",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = tokenizer.batch_decode(\n",
    "    generated_ids,\n",
    "    skip_special_tokens = True\n",
    ")[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7f88ff5f-1968-494f-83b7-792ea072ef37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LM 和 LMM 是两种不同的模型训练方法，它们在处理自然语言问题时有不同的特点和适用场景。\n",
      "\n",
      "1. **LM（Language Model）**：\n",
      "   - LM 模型主要关注的是生成文本的任务。例如，在机器翻译、情感分析、问答系统等任务中，LM 会尝试预测下一个词或短语的含义。\n",
      "   - LM 的输出通常是基于预训练的语言模型来生成的。它通常使用预定义的规则或者特定的算法来决定生成的文本内容。\n",
      "   - LM 可以用于生成文章、评论、报告等各种类型的文本。\n",
      "\n",
      "2. **LMM（Large Language Model）**：\n",
      "   - LMM 相比于 LM 更加强大，它可以学习到更丰富的知识，并且可以进行更复杂的任务。LMM 不仅能够生成文本，还可以理解上下文信息，甚至理解和预测其他类型的自然语言问题。\n",
      "   - LMM 通过大量的数据训练来提高其对不同领域知识的理解能力。LMM 还具有更强的学习能力和推理能力，能够在面对复杂问题时表现出色。\n",
      "   - LMM 可以应用于各种应用领域，如图像识别、语音识别、自然语言理解和对话系统等。\n",
      "\n",
      "总结来说，LM 主要用于生成文本，而 LMM 则是大模型技术的一种，可以进行更加全面和复杂的任务，包括但不限于理解、推理、学习等。两者都是自然语言处理领域的核心技术，各有千秋。\n"
     ]
    }
   ],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f146281-aae4-4726-86ba-c8d0e2f00a0f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

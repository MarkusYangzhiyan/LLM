import numpy as np
import matplotlib.pyplot as plt
from tensorflow.keras.datasets import cifar10

# å¯¼å…¥æ¨¡å—
from linear import Linear
from activations import ReLU
from loss import CrossEntropyloss
from optimizer import Adam, SGD
from dropout import Dropout
from batchnorm import BatchNorm
from utils import calculate_accuracy
from dataloader import DataLoader

# å¤ç”¨ Sequential (åŒä¸Šï¼Œè¯·ç¡®ä¿æœ‰å®šä¹‰)
class Sequential:
    def __init__(self, layers): self.layers = layers
    def forward(self, x): 
        for l in self.layers: x = l.forward(x)
        return x
    def backward(self, g): 
        for l in reversed(self.layers): g = l.backward(g)
    def train(self): 
        for l in self.layers: l.train()
    def eval(self): 
        for l in self.layers: l.eval()
    def get_params(self): return [p for l in self.layers if hasattr(l,'params') for v in l.params.values() for p in [v]]
    def get_grads(self): return [g for l in self.layers if hasattr(l,'params') for v in l.grads.values() for g in [v]]

def build_cifar_net():
    # è¾“å…¥ 3072 (32*32*3) -> å®½ç½‘ç»œ 1024 -> 256 -> 10
    return Sequential([
        Linear(3072, 1024), BatchNorm(1024), ReLU(), Dropout(0.2),
        Linear(1024, 256), BatchNorm(256), ReLU(), Dropout(0.2),
        Linear(256, 10)
    ])

def run_experiment(name, opt_class, lr, x_train, y_train, x_test, y_test):
    print(f"ðŸ–¼ï¸ å¼€å§‹è®­ç»ƒ: {name} (CIFAR-10 ä¼šæ¯”è¾ƒæ…¢ï¼Œè¯·è€å¿ƒ...)")
    np.random.seed(42)
    model = build_cifar_net()
    criterion = CrossEntropyloss()
    
    if name == "SGD": optimizer = opt_class(model.get_params(), lr=lr, momentum=0.9)
    else: optimizer = opt_class(model.get_params(), lr=lr)

    # ç¨å¾®åŠ å¤§ Batch Size ä»¥åˆ©ç”¨çŸ©é˜µä¹˜æ³•åŠ é€Ÿ
    train_loader = DataLoader(x_train, y_train, batch_size=256, shuffle=True)
    test_loader = DataLoader(x_test, y_test, batch_size=256, shuffle=False)
    
    history = []
    
    # åªè·‘ 3 ä¸ª Epoch æ¼”ç¤ºæ•ˆæžœï¼Œå¦åˆ™å¤ªæ…¢
    for epoch in range(3): 
        model.train()
        total_loss = 0
        for i, (x_b, y_b) in enumerate(train_loader):
            logits = model.forward(x_b)
            loss = criterion.forward(logits, y_b)
            model.backward(criterion.backward())
            optimizer.step(model.get_grads())
            total_loss += loss
            
            # æ‰“å°è¿›åº¦æ¡ï¼Œå› ä¸ºCIFARå¾ˆæ…¢
            if i % 50 == 0: print(f"   Step {i} Loss: {loss:.4f}")

        # æµ‹è¯•
        model.eval()
        correct = 0
        total = 0
        for x_b, y_b in test_loader:
            out = model.forward(x_b)
            correct += calculate_accuracy(out, y_b) * x_b.shape[0]
            total += x_b.shape[0]
            
        acc = correct / total
        history.append(acc)
        print(f"   Epoch {epoch+1} Test Acc: {acc:.4f}")
        
    return history

if __name__ == "__main__":
    (x_train, y_train), (x_test, y_test) = cifar10.load_data()
    
    # é¢„å¤„ç†ï¼šFlatten (N, 32, 32, 3) -> (N, 3072)
    x_train = x_train.reshape(x_train.shape[0], -1).astype(np.float32) / 255.0
    x_test = x_test.reshape(x_test.shape[0], -1).astype(np.float32) / 255.0
    y_train = y_train.flatten()
    y_test = y_test.flatten()

    # å¯¹æ¯”
    acc_sgd = run_experiment("SGD", SGD, 0.01, x_train, y_train, x_test, y_test)
    acc_adam = run_experiment("Adam", Adam, 0.001, x_train, y_train, x_test, y_test)

    plt.plot(acc_sgd, label='SGD')
    plt.plot(acc_adam, label='Adam')
    plt.title('CIFAR-10 Accuracy (3 Epochs)')
    plt.legend()
    plt.show()